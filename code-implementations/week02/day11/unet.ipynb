{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5ecf32",
   "metadata": {},
   "source": [
    "11일차 실습: U-Net으로 의료영상 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8444511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score\n",
    "import time\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "device = torch.device('cpu')\n",
    "import os\n",
    "import sys\n",
    "if sys.platform.startswith('win'):\n",
    "    import multiprocessing\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "print(\"Windows 환경 설정 완료\")\n",
    "\n",
    "# CPU 강제 사용 (가장 안전)\n",
    "device = torch.device('cpu')\n",
    "print(f\"Device: {device} (Windows 안전 모드)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afddfc1",
   "metadata": {},
   "source": [
    "1. U-Net 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00311c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"U-Net의 기본 블록: Conv -> ReLU -> Conv -> ReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling: MaxPool -> DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling: ConvTranspose -> Concat -> DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            # Bilinear upsampling 사용\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "        else:\n",
    "            # Transposed convolution 사용 (원논문 방식)\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        # x1: 이전 레이어에서 올라온 특징\n",
    "        # x2: Skip connection에서 오는 특징\n",
    "        \n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # 크기가 안 맞을 경우 패딩 (입력 크기가 2의 배수가 아닐 때)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Skip connection: 채널 차원으로 concatenate\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"완전한 U-Net 아키텍처\"\"\"\n",
    "    def __init__(self, n_channels=1, n_classes=2, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        # Encoder (Contracting path)\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        \n",
    "        # Decoder (Expansive path)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        \n",
    "        # Output layer\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)      # 64 channels\n",
    "        x2 = self.down1(x1)   # 128 channels  \n",
    "        x3 = self.down2(x2)   # 256 channels\n",
    "        x4 = self.down3(x3)   # 512 channels\n",
    "        x5 = self.down4(x4)   # 1024 channels (bottleneck)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = self.up1(x5, x4)  # 512 channels\n",
    "        x = self.up2(x, x3)   # 256 channels\n",
    "        x = self.up3(x, x2)   # 128 channels  \n",
    "        x = self.up4(x, x1)   # 64 channels\n",
    "        \n",
    "        # Output\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d43d0",
   "metadata": {},
   "source": [
    "2. 의료영상 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungCTDataset(Dataset):\n",
    "    \"\"\"폐 CT 데이터셋\"\"\"\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, is_train=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # 실제로는 파일 리스트를 읽어옴\n",
    "        # 여기서는 가상의 데이터셋 크기 설정\n",
    "        self.length = 1000 if is_train else 200\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 실제 환경에서는 실제 파일을 읽음\n",
    "        # 여기서는 가상 데이터 생성 (512x512 크기)\n",
    "        \n",
    "        # 가상 CT 이미지 생성 (폐 모양)\n",
    "        image = self.generate_fake_ct_image()\n",
    "        \n",
    "        # 가상 마스크 생성 (폐 영역)\n",
    "        mask = self.generate_fake_lung_mask()\n",
    "        \n",
    "        # PIL Image로 변환\n",
    "        image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "        mask = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            # 마스크는 interpolation 없이 변환\n",
    "            mask_transform = transforms.Compose([\n",
    "                transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            mask = mask_transform(mask)\n",
    "        \n",
    "        # 마스크를 0, 1로 확실히 변환\n",
    "        mask = (mask > 0.5).long().squeeze(0)  # [H, W], 값은 0 또는 1\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def generate_fake_ct_image(self):\n",
    "        \"\"\"가상 CT 이미지 생성\"\"\"\n",
    "        img = np.random.randn(512, 512) * 0.1 + 0.3\n",
    "        \n",
    "        # 폐 모양 추가\n",
    "        center_y, center_x = 256, 256\n",
    "        y, x = np.ogrid[:512, :512]\n",
    "        \n",
    "        # 왼쪽 폐\n",
    "        left_lung = ((x - 180)**2 + (y - 200)**2) < 80**2\n",
    "        img[left_lung] += 0.4\n",
    "        \n",
    "        # 오른쪽 폐  \n",
    "        right_lung = ((x - 330)**2 + (y - 200)**2) < 75**2\n",
    "        img[right_lung] += 0.4\n",
    "        \n",
    "        # 노이즈 추가\n",
    "        img += np.random.randn(512, 512) * 0.05\n",
    "        \n",
    "        return np.clip(img, 0, 1)\n",
    "    \n",
    "    def generate_fake_lung_mask(self):\n",
    "        \"\"\"가상 폐 마스크 생성\"\"\"\n",
    "        mask = np.zeros((512, 512))\n",
    "        \n",
    "        # 왼쪽 폐 마스크\n",
    "        y, x = np.ogrid[:512, :512]\n",
    "        left_lung = ((x - 180)**2 + (y - 200)**2) < 80**2\n",
    "        mask[left_lung] = 1\n",
    "        \n",
    "        # 오른쪽 폐 마스크\n",
    "        right_lung = ((x - 330)**2 + (y - 200)**2) < 75**2\n",
    "        mask[right_lung] = 1\n",
    "        \n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8938f0",
   "metadata": {},
   "source": [
    "3. 데이터 전처리 및 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f99e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    \"\"\"데이터 전처리 파이프라인\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # [-1, 1] 정규화\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "def create_data_loaders(batch_size=4):\n",
    "    \"\"\"데이터 로더 생성\"\"\"\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # 실제로는 실제 데이터 경로 사용\n",
    "    train_dataset = LungCTDataset(\n",
    "        image_dir=\"train/images\", \n",
    "        mask_dir=\"train/masks\",\n",
    "        transform=train_transform,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = LungCTDataset(\n",
    "        image_dir=\"val/images\",\n",
    "        mask_dir=\"val/masks\", \n",
    "        transform=val_transform,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db82c6",
   "metadata": {},
   "source": [
    "4. 손실함수 및 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss - 의료영상 분할에서 많이 사용\"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # predictions: [B, C, H, W]\n",
    "        # targets: [B, H, W]\n",
    "        \n",
    "        # 타겟 값 범위 확인\n",
    "        targets = torch.clamp(targets, 0, predictions.shape[1] - 1)\n",
    "        \n",
    "        # Softmax 적용\n",
    "        predictions = F.softmax(predictions, dim=1)\n",
    "        \n",
    "        # 각 클래스별로 Dice 계산\n",
    "        dice_scores = []\n",
    "        \n",
    "        for c in range(predictions.shape[1]):\n",
    "            pred_c = predictions[:, c, :, :]  # [B, H, W]\n",
    "            target_c = (targets == c).float()  # [B, H, W]\n",
    "            \n",
    "            intersection = (pred_c * target_c).sum()\n",
    "            union = pred_c.sum() + target_c.sum()\n",
    "            \n",
    "            dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        return 1.0 - torch.mean(torch.stack(dice_scores))\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Cross Entropy + Dice Loss 조합\"\"\"\n",
    "    def __init__(self, ce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        ce = self.ce_loss(predictions, targets)\n",
    "        dice = self.dice_loss(predictions, targets)\n",
    "        return self.ce_weight * ce + self.dice_weight * dice\n",
    "\n",
    "def calculate_iou(pred, target, num_classes=2):\n",
    "    \"\"\"IoU (Intersection over Union) 계산\"\"\"\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        pred_c = (pred == c)\n",
    "        target_c = (target == c)\n",
    "        \n",
    "        intersection = (pred_c & target_c).sum().float()\n",
    "        union = (pred_c | target_c).sum().float()\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = 1.0  # 해당 클래스가 없는 경우\n",
    "        else:\n",
    "            iou = intersection / union\n",
    "        \n",
    "        ious.append(iou.item())\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f1a25",
   "metadata": {},
   "source": [
    "5. 학습 및 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"한 에포크 학습\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (images, masks) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # 마스크 값 범위 확인 및 보정\n",
    "        masks = torch.clamp(masks, 0, 1)  # 0과 1 사이로 제한\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n",
    "            # 디버깅 정보\n",
    "            print(f'  Image range: [{images.min():.3f}, {images.max():.3f}]')\n",
    "            print(f'  Mask range: [{masks.min():.0f}, {masks.max():.0f}]')\n",
    "            print(f'  Mask unique values: {masks.unique()}')\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_iou = [0, 0]  # [background, lung]\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # 예측값 계산\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # IoU 계산\n",
    "            batch_iou = calculate_iou(pred_masks, masks)\n",
    "            total_iou[0] += batch_iou[0]\n",
    "            total_iou[1] += batch_iou[1]\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_iou = [iou / num_batches for iou in total_iou]\n",
    "    \n",
    "    return avg_loss, avg_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45643baa",
   "metadata": {},
   "source": [
    "6. 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22125d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataloader, device, num_samples=4):\n",
    "    \"\"\"예측 결과 시각화\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # CPU로 이동 및 시각화\n",
    "            images = images.cpu()\n",
    "            masks = masks.cpu()\n",
    "            pred_masks = pred_masks.cpu()\n",
    "            \n",
    "            fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "            \n",
    "            for i in range(min(num_samples, images.shape[0])):\n",
    "                # 원본 이미지\n",
    "                img = images[i, 0].numpy()\n",
    "                img = (img + 1) / 2  # [-1,1] -> [0,1]\n",
    "                axes[i, 0].imshow(img, cmap='gray')\n",
    "                axes[i, 0].set_title('Original CT Image')\n",
    "                axes[i, 0].axis('off')\n",
    "                \n",
    "                # 정답 마스크\n",
    "                true_mask = masks[i].numpy()\n",
    "                axes[i, 1].imshow(true_mask, cmap='jet', alpha=0.8)\n",
    "                axes[i, 1].set_title('Ground Truth Mask')\n",
    "                axes[i, 1].axis('off')\n",
    "                \n",
    "                # 예측 마스크\n",
    "                pred_mask = pred_masks[i].numpy()\n",
    "                axes[i, 2].imshow(pred_mask, cmap='jet', alpha=0.8)\n",
    "                axes[i, 2].set_title('Predicted Mask')\n",
    "                axes[i, 2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, val_ious):\n",
    "    \"\"\"학습 과정 시각화\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss 그래프\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # IoU 그래프\n",
    "    lung_ious = [iou[1] for iou in val_ious]  # 폐 영역 IoU만\n",
    "    ax2.plot(epochs, lung_ious, 'g-', label='Lung IoU')\n",
    "    ax2.set_title('Validation IoU (Lung)')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('IoU')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f6352",
   "metadata": {},
   "source": [
    "7. 메인 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"메인 함수\"\"\"\n",
    "    print(\"=== U-Net 의료영상 분할 실습 시작 ===\")\n",
    "    \n",
    "    # 하이퍼파라미터\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCHS = 20\n",
    "    LEARNING_RATE = 1e-4\n",
    "    \n",
    "    # 데이터 로더 생성\n",
    "    print(\"데이터 로더 생성 중...\")\n",
    "    train_loader, val_loader = create_data_loaders(BATCH_SIZE)\n",
    "    \n",
    "    # 모델 생성\n",
    "    print(\"U-Net 모델 생성 중...\")\n",
    "    model = UNet(n_channels=1, n_classes=2, bilinear=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 모델 파라미터 수 출력\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"모델 파라미터 수: {total_params:,}\")\n",
    "    \n",
    "    # 손실함수 및 옵티마이저\n",
    "    criterion = CombinedLoss(ce_weight=0.4, dice_weight=0.6)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "    \n",
    "    # 학습 기록\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_ious = []\n",
    "    \n",
    "    best_iou = 0.0\n",
    "    \n",
    "    print(\"학습 시작!\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 학습\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # 검증\n",
    "        val_loss, val_iou = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # 학습률 스케줄러\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 기록 저장\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_ious.append(val_iou)\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_iou[1] > best_iou:\n",
    "            best_iou = val_iou[1]\n",
    "            torch.save(model.state_dict(), 'best_unet_model.pth')\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}]')\n",
    "        print(f'  Train Loss: {train_loss:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}')\n",
    "        print(f'  Val IoU - Background: {val_iou[0]:.4f}, Lung: {val_iou[1]:.4f}')\n",
    "        print(f'  Time: {epoch_time:.2f}s')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    print(f\"학습 완료! 최고 Lung IoU: {best_iou:.4f}\")\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plot_training_history(train_losses, val_losses, val_ious)\n",
    "    \n",
    "    # 예측 결과 시각화\n",
    "    print(\"예측 결과 시각화...\")\n",
    "    model.load_state_dict(torch.load('best_unet_model.pth'))\n",
    "    visualize_predictions(model, val_loader, device)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 실습 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # Windows multiprocessing 지원을 위해 필수\n",
    "    if os.name == 'nt':  # Windows\n",
    "        import multiprocessing\n",
    "        multiprocessing.set_start_method('spawn', force=True)\n",
    "    \n",
    "    model = main()\n",
    "    \n",
    "    print(\"\\n=== 실습 완료 ===\")\n",
    "    print(\"주요 학습 포인트:\")\n",
    "    print(\"1. U-Net의 Skip Connection 효과\")\n",
    "    print(\"2. 의료영상에서 Dice Loss의 중요성\") \n",
    "    print(\"3. IoU를 통한 분할 성능 평가\")\n",
    "    print(\"4. 데이터 증강의 필요성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ea595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "start",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
