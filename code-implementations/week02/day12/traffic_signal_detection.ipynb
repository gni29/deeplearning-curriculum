{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a16aa4",
   "metadata": {},
   "source": [
    "êµí†µ í‘œì§€íŒ íƒì§€ ì‹œìŠ¤í…œ ì‹¤ìŠµ ê°€ì´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ë¹„í™œì„±í™” (ì—ëŸ¬ ë°©ì§€)\n",
    "def nuclear_mlflow_disable():\n",
    "    \"\"\"MLflow ê´€ë ¨ ëª¨ë“  ê²ƒì„ ì™„ì „íˆ ë¹„í™œì„±í™”\"\"\"\n",
    "    \n",
    "    print(\"ğŸš« Completely disabling MLflow...\")\n",
    "    \n",
    "    # 1. ëª¨ë“  MLflow í™˜ê²½ë³€ìˆ˜ ì œê±°/ì„¤ì •\n",
    "    mlflow_vars = [\n",
    "        'MLFLOW_TRACKING_URI',\n",
    "        'MLFLOW_REGISTRY_URI', \n",
    "        'MLFLOW_DEFAULT_ARTIFACT_ROOT',\n",
    "        'MLFLOW_BACKEND_STORE_URI',\n",
    "        'MLFLOW_ARTIFACT_URI',\n",
    "        'MLFLOW_S3_ENDPOINT_URL',\n",
    "        'MLFLOW_EXPERIMENT_ID',\n",
    "        'MLFLOW_RUN_ID'\n",
    "    ]\n",
    "    \n",
    "    for var in mlflow_vars:\n",
    "        if var in os.environ:\n",
    "            del os.environ[var]\n",
    "        os.environ[var] = ''\n",
    "    \n",
    "    # 2. ì¶”ê°€ ë¹„í™œì„±í™” í”Œë˜ê·¸ë“¤\n",
    "    os.environ['DISABLE_MLFLOW'] = '1'\n",
    "    os.environ['NO_MLFLOW'] = '1'\n",
    "    os.environ['MLFLOW_DISABLE'] = '1'\n",
    "    os.environ['MLFLOW_DISABLE_ENV_CREATION'] = '1'\n",
    "    \n",
    "    # 3. runs í´ë” ì™„ì „ ì‚­ì œ\n",
    "    runs_paths = [\n",
    "        Path('./runs'),\n",
    "        Path('./mlflow'),\n",
    "        Path('C:/Users/JPJ/deeplearning-curriculum/runs'),\n",
    "        Path('C:/Users/JPJ/deeplearning-curriculum/mlflow'),\n",
    "    ]\n",
    "    \n",
    "    for runs_path in runs_paths:\n",
    "        if runs_path.exists():\n",
    "            try:\n",
    "                shutil.rmtree(runs_path, ignore_errors=True)\n",
    "                print(f\"ğŸ—‘ï¸ Removed: {runs_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Could not remove {runs_path}: {e}\")\n",
    "    \n",
    "    # 4. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½ (MLflow ì„¤ì • íšŒí”¼)\n",
    "    original_dir = os.getcwd()\n",
    "    temp_dir = Path.home() / 'temp_yolo_training'\n",
    "    temp_dir.mkdir(exist_ok=True)\n",
    "    os.chdir(temp_dir)\n",
    "    print(f\"ğŸ“ Changed working directory to: {temp_dir}\")\n",
    "    \n",
    "    # 5. MLflow import ì™„ì „ ì°¨ë‹¨\n",
    "    class MLflowBlocker:\n",
    "        def find_spec(self, name, path, target=None):\n",
    "            if 'mlflow' in name.lower():\n",
    "                print(f\"ğŸš« Blocked MLflow import: {name}\")\n",
    "                return None\n",
    "        def find_module(self, name, path=None):\n",
    "            if 'mlflow' in name.lower():\n",
    "                print(f\"ğŸš« Blocked MLflow import: {name}\")\n",
    "                return None\n",
    "    \n",
    "    # MLflow ì°¨ë‹¨ê¸° ì„¤ì¹˜\n",
    "    if not any(isinstance(finder, MLflowBlocker) for finder in sys.meta_path):\n",
    "        sys.meta_path.insert(0, MLflowBlocker())\n",
    "    \n",
    "    print(\"âœ… MLflow completely neutralized\")\n",
    "    return original_dir    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e598d",
   "metadata": {},
   "source": [
    "1ë‹¨ê³„: Roboflowë¡œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_traffic_dataset_roboflow():\n",
    "    \"\"\"Roboflowì—ì„œ êµí†µí‘œì§€íŒ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\"\"\"\n",
    "    \n",
    "    try:\n",
    "        from roboflow import Roboflow\n",
    "        \n",
    "        print(\"ğŸ”„ Downloading traffic sign dataset from Roboflow...\")\n",
    "        \n",
    "        # Roboflow API ì‚¬ìš©\n",
    "        rf = Roboflow(api_key=\"qsoKXZgHZOA51nr36zzD\")  # ì‹¤ì œ API í‚¤ë¡œ êµì²´\n",
    "        project = rf.workspace(\"augmented-startups\").project(\"traffic-sign-detection-yolov8\")\n",
    "        dataset = project.version(1).download(\"yolov8\")\n",
    "        \n",
    "        print(\"âœ… Dataset downloaded successfully!\")\n",
    "        return dataset.location\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Roboflow download failed: {e}\")\n",
    "        print(\"ğŸ“¥ Creating sample dataset instead...\")\n",
    "        return create_sample_dataset()\n",
    "\n",
    "def create_sample_dataset():\n",
    "    \"\"\"ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± (Roboflow ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ)\"\"\"\n",
    "    print(\"ğŸ”§ Creating sample dataset...\")\n",
    "    \n",
    "    dataset_name = \"traffic-signs-sample\"\n",
    "    base_path = Path(dataset_name)\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        (base_path / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (base_path / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "    sample_images = [\n",
    "        \"https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/bus.jpg\",\n",
    "        \"https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg\",\n",
    "    ]\n",
    "    \n",
    "    for i, url in enumerate(sample_images):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ì €ì¥\n",
    "            img_name = f\"sample_{i:03d}.jpg\"\n",
    "            for split in ['train', 'valid']:\n",
    "                img_path = base_path / split / 'images' / img_name\n",
    "                with open(img_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                \n",
    "                # ë”ë¯¸ ë¼ë²¨ ìƒì„± (YOLO í¬ë§·)\n",
    "                label_path = base_path / split / 'labels' / f\"sample_{i:03d}.txt\"\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write(\"0 0.5 0.5 0.3 0.3\\n\")  # class x_center y_center width height\n",
    "                    \n",
    "            print(f\"âœ… Downloaded sample image {i+1}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to download sample {i}: {e}\")\n",
    "    \n",
    "    # data.yaml ìƒì„±\n",
    "    data_yaml_content = f\"\"\"\n",
    "path: {base_path.absolute()}\n",
    "train: train/images\n",
    "val: valid/images\n",
    "test: test/images\n",
    "\n",
    "nc: 5\n",
    "names: ['speed_limit_30', 'speed_limit_50', 'stop_sign', 'no_entry', 'yield']\n",
    "\"\"\"\n",
    "    \n",
    "    with open(base_path / 'data.yaml', 'w') as f:\n",
    "        f.write(data_yaml_content.strip())\n",
    "    \n",
    "    print(f\"âœ… Sample dataset created at: {base_path}\")\n",
    "    return str(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cabc6f",
   "metadata": {},
   "source": [
    "2ë‹¨ê³„: YOLOv11 ëª¨ë¸ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolov11_model(dataset_path, model_size='n', epochs=50):\n",
    "\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    print(f\"ğŸš€ Training YOLOv11{model_size} model...\")\n",
    "    \n",
    "    # ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"ğŸ’» Using device: {device}\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •\n",
    "    if device == 'cuda':\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB\n",
    "        if gpu_memory < 6:\n",
    "            batch_size = 8\n",
    "        elif gpu_memory < 12:\n",
    "            batch_size = 16\n",
    "        else:\n",
    "            batch_size = 32\n",
    "        print(f\"ğŸ”§ GPU Memory: {gpu_memory:.1f}GB, Batch size: {batch_size}\")\n",
    "    else:\n",
    "        batch_size = 4\n",
    "        print(f\"ğŸ”§ CPU mode, Batch size: {batch_size}\")\n",
    "    \n",
    "    # YOLOv11 ëª¨ë¸ ë¡œë“œ\n",
    "    try:\n",
    "        model = YOLO(f'yolo11{model_size}.pt')\n",
    "        print(f\"âœ… YOLOv11{model_size} model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load YOLOv11{model_size}: {e}\")\n",
    "        print(\"ğŸ”„ Trying YOLOv8 as fallback...\")\n",
    "        model = YOLO(f'yolov8{model_size}.pt')\n",
    "        print(f\"âœ… YOLOv8{model_size} fallback loaded\")\n",
    "    \n",
    "    # MLflow ê´€ë ¨ ì„¤ì • ì œê±°\n",
    "    print(f\"ğŸƒâ€â™‚ï¸ Starting training for {epochs} epochs...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=f'{dataset_path}/data.yaml',\n",
    "            epochs=epochs,\n",
    "            batch=batch_size,\n",
    "            imgsz=640,\n",
    "            device=device,\n",
    "            patience=15,\n",
    "            save=True,\n",
    "            project='traffic_signs_yolov11',\n",
    "            name=f'yolo11{model_size}_experiment',\n",
    "            verbose=True,\n",
    "            \n",
    "            # ì„±ëŠ¥ ìµœì í™”\n",
    "            cache='disk',             # RAM ëŒ€ì‹  disk ìºì‹œ (MLflow ì—ëŸ¬ ë°©ì§€)\n",
    "            amp=device=='cuda',       # Automatic Mixed Precision (GPUë§Œ)\n",
    "            workers=4 if device=='cuda' else 2,  # ë°ì´í„° ë¡œë” ì›Œì»¤\n",
    "            \n",
    "            # ë°ì´í„° ì¦ê°•\n",
    "            hsv_h=0.015,\n",
    "            hsv_s=0.7,\n",
    "            hsv_v=0.4,\n",
    "            degrees=10,\n",
    "            translate=0.1,\n",
    "            scale=0.5,\n",
    "            flipud=0.0,\n",
    "            fliplr=0.5,\n",
    "            \n",
    "            # í•™ìŠµ ì„¤ì •\n",
    "            optimizer='AdamW',\n",
    "            lr0=0.001,\n",
    "            weight_decay=0.0005,\n",
    "            \n",
    "            # MLflow ë¹„í™œì„±í™”\n",
    "            plots=False,              # plots ë¹„í™œì„±í™”ë¡œ MLflow ìš°íšŒ\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"âœ… Training completed in {training_time/60:.1f} minutes\")\n",
    "        \n",
    "        return model, results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Training failed: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1145ee26",
   "metadata": {},
   "source": [
    "3ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c643af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model, dataset_path):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© í‰ê°€\"\"\"\n",
    "    print(\"ğŸ“Š Evaluating model performance...\")\n",
    "    \n",
    "    try:\n",
    "        # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€\n",
    "        val_results = model.val(data=f'{dataset_path}/data.yaml', verbose=False)\n",
    "        \n",
    "        # ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ\n",
    "        performance_metrics = {\n",
    "            'mAP50': float(val_results.box.map50) if hasattr(val_results.box, 'map50') else 0.0,\n",
    "            'mAP50_95': float(val_results.box.map) if hasattr(val_results.box, 'map') else 0.0,\n",
    "            'precision': float(val_results.box.mp) if hasattr(val_results.box, 'mp') else 0.0,\n",
    "            'recall': float(val_results.box.mr) if hasattr(val_results.box, 'mr') else 0.0,\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ“ˆ Performance Metrics:\")\n",
    "        print(f\"   mAP@0.5: {performance_metrics['mAP50']:.3f}\")\n",
    "        print(f\"   mAP@0.5:0.95: {performance_metrics['mAP50_95']:.3f}\")\n",
    "        print(f\"   Precision: {performance_metrics['precision']:.3f}\")\n",
    "        print(f\"   Recall: {performance_metrics['recall']:.3f}\")\n",
    "        \n",
    "        return performance_metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Evaluation failed: {e}\")\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "\n",
    "def measure_inference_speed(model, dataset_path, num_samples=20):\n",
    "    \"\"\"ì¶”ë¡  ì†ë„ ì¸¡ì •\"\"\"\n",
    "    print(\"â±ï¸ Measuring inference speed...\")\n",
    "    \n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜ì§‘\n",
    "        test_dir = Path(dataset_path) / 'test' / 'images'\n",
    "        if not test_dir.exists():\n",
    "            test_dir = Path(dataset_path) / 'valid' / 'images'\n",
    "        \n",
    "        test_images = list(test_dir.glob('*.jpg'))[:num_samples]\n",
    "        \n",
    "        if not test_images:\n",
    "            print(\"âŒ No test images found\")\n",
    "            return {'fps': 0.0, 'avg_time': 0.0}\n",
    "        \n",
    "        # ì¶”ë¡  ì‹œê°„ ì¸¡ì •\n",
    "        times = []\n",
    "        \n",
    "        for img_path in test_images:\n",
    "            start_time = time.time()\n",
    "            results = model.predict(source=str(img_path), verbose=False, save=False)\n",
    "            end_time = time.time()\n",
    "            times.append(end_time - start_time)\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        fps = 1.0 / avg_time if avg_time > 0 else 0.0\n",
    "        \n",
    "        print(f\"ğŸš€ Inference Speed:\")\n",
    "        print(f\"   Average time per image: {avg_time:.3f}s\")\n",
    "        print(f\"   FPS: {fps:.1f}\")\n",
    "        \n",
    "        return {\n",
    "            'fps': fps,\n",
    "            'avg_time': avg_time,\n",
    "            'total_images': len(test_images)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Speed measurement failed: {e}\")\n",
    "        return {'fps': 0.0, 'avg_time': 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac23f4a",
   "metadata": {},
   "source": [
    "4ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(project_path):\n",
    "    \"\"\"í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    print(\"ğŸ“ˆ Visualizing training results...\")\n",
    "    \n",
    "    results_path = Path(project_path) / \"results.csv\"\n",
    "    \n",
    "    if not results_path.exists():\n",
    "        print(f\"âŒ Results file not found: {results_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(results_path)\n",
    "        \n",
    "        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "        plt.style.use('seaborn-v0_8')\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # 1. Loss ê³¡ì„ \n",
    "        if 'train/box_loss' in df.columns and 'val/box_loss' in df.columns:\n",
    "            axes[0,0].plot(df['epoch'], df['train/box_loss'], \n",
    "                          label='Train Box Loss', color='#2E86AB', linewidth=2)\n",
    "            axes[0,0].plot(df['epoch'], df['val/box_loss'], \n",
    "                          label='Val Box Loss', color='#A23B72', linewidth=2)\n",
    "            axes[0,0].set_title('Box Loss During Training', fontsize=14, fontweight='bold')\n",
    "            axes[0,0].set_xlabel('Epoch')\n",
    "            axes[0,0].set_ylabel('Loss')\n",
    "            axes[0,0].legend()\n",
    "            axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. mAP ê³¡ì„ \n",
    "        map_cols = [col for col in df.columns if 'mAP' in col and 'val' in col]\n",
    "        if map_cols:\n",
    "            for i, col in enumerate(map_cols[:2]):\n",
    "                color = ['#F18F01', '#C73E1D'][i]\n",
    "                axes[0,1].plot(df['epoch'], df[col], \n",
    "                              label=col.replace('val/', ''), color=color, linewidth=2)\n",
    "            axes[0,1].set_title('Mean Average Precision', fontsize=14, fontweight='bold')\n",
    "            axes[0,1].set_xlabel('Epoch')\n",
    "            axes[0,1].set_ylabel('mAP')\n",
    "            axes[0,1].legend()\n",
    "            axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. ì •ë°€ë„/ì¬í˜„ìœ¨\n",
    "        precision_cols = [col for col in df.columns if 'precision' in col and 'val' in col]\n",
    "        recall_cols = [col for col in df.columns if 'recall' in col and 'val' in col]\n",
    "        \n",
    "        if precision_cols and recall_cols:\n",
    "            axes[1,0].plot(df['epoch'], df[precision_cols[0]], \n",
    "                          label='Precision', color='#3D5A80', linewidth=2)\n",
    "            axes[1,0].plot(df['epoch'], df[recall_cols[0]], \n",
    "                          label='Recall', color='#98C1D9', linewidth=2)\n",
    "            axes[1,0].set_title('Precision and Recall', fontsize=14, fontweight='bold')\n",
    "            axes[1,0].set_xlabel('Epoch')\n",
    "            axes[1,0].set_ylabel('Score')\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. í•™ìŠµë¥ \n",
    "        lr_cols = [col for col in df.columns if 'lr' in col]\n",
    "        if lr_cols:\n",
    "            axes[1,1].plot(df['epoch'], df[lr_cols[0]], \n",
    "                          label='Learning Rate', color='#E63946', linewidth=2)\n",
    "            axes[1,1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "            axes[1,1].set_xlabel('Epoch')\n",
    "            axes[1,1].set_ylabel('Learning Rate')\n",
    "            axes[1,1].legend()\n",
    "            axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = Path(project_path) / 'training_analysis.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… Training visualization saved to: {save_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Visualization failed: {e}\")\n",
    "\n",
    "def visualize_detection_results(model, dataset_path, num_samples=6):\n",
    "    \"\"\"ìƒ˜í”Œ ì´ë¯¸ì§€ì—ì„œ íƒì§€ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    print(\"ğŸ¯ Visualizing detection results...\")\n",
    "    \n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°\n",
    "        test_dir = Path(dataset_path) / 'test' / 'images'\n",
    "        if not test_dir.exists():\n",
    "            test_dir = Path(dataset_path) / 'valid' / 'images'\n",
    "        \n",
    "        test_images = list(test_dir.glob('*.jpg'))[:num_samples]\n",
    "        \n",
    "        if not test_images:\n",
    "            print(\"âŒ No test images found\")\n",
    "            return\n",
    "        \n",
    "        # ê·¸ë¦¬ë“œ í¬ê¸° ê³„ì‚°\n",
    "        cols = min(3, len(test_images))\n",
    "        rows = (len(test_images) + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "        if rows == 1 and cols == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1:\n",
    "            axes = axes\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        for i, img_path in enumerate(test_images):\n",
    "            # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            results = model.predict(source=str(img_path), save=False, verbose=False)\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "            if len(results) > 0 and results[0].boxes is not None:\n",
    "                boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "                confs = results[0].boxes.conf.cpu().numpy()\n",
    "                classes = results[0].boxes.cls.cpu().numpy() if results[0].boxes.cls is not None else []\n",
    "                \n",
    "                for box, conf in zip(boxes, confs):\n",
    "                    if conf > 0.3:  # ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    "                        x1, y1, x2, y2 = box.astype(int)\n",
    "                        \n",
    "                        # ë°”ìš´ë”© ë°•ìŠ¤\n",
    "                        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "                        \n",
    "                        # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸\n",
    "                        text = f'{conf:.2f}'\n",
    "                        cv2.putText(img_rgb, text, (x1, y1-10), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            \n",
    "            # ê²°ê³¼ í‘œì‹œ\n",
    "            if i < len(axes):\n",
    "                axes[i].imshow(img_rgb)\n",
    "                axes[i].set_title(f'Detection Result {i+1}', fontweight='bold')\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°\n",
    "        for j in range(len(test_images), len(axes)):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('detection_results.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"âœ… Detection results saved to: detection_results.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Detection visualization failed: {e}\")\n",
    "\n",
    "def compare_model_sizes(dataset_path, model_sizes=['n', 's'], epochs=10):\n",
    "    \"\"\"ì—¬ëŸ¬ ëª¨ë¸ í¬ê¸° ë¹„êµ\"\"\"\n",
    "    print(\"ğŸ† Comparing different model sizes...\")\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    for size in model_sizes:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training YOLOv11{size}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # ëª¨ë¸ í›ˆë ¨\n",
    "        model, results = train_yolov11_model(dataset_path, size, epochs)\n",
    "        \n",
    "        if model is None:\n",
    "            continue\n",
    "        \n",
    "        # ì„±ëŠ¥ í‰ê°€\n",
    "        performance = evaluate_model_performance(model, dataset_path)\n",
    "        speed = measure_inference_speed(model, dataset_path)\n",
    "        \n",
    "        # ëª¨ë¸ í¬ê¸° ì •ë³´\n",
    "        model_sizes_mb = {'n': 6, 's': 22, 'm': 52, 'l': 131, 'x': 218}\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'Model': f'YOLOv11{size}',\n",
    "            'mAP50': performance['mAP50'],\n",
    "            'mAP50_95': performance['mAP50_95'],\n",
    "            'Precision': performance['precision'],\n",
    "            'Recall': performance['recall'],\n",
    "            'FPS': speed['fps'],\n",
    "            'Avg_Time': speed['avg_time'],\n",
    "            'Model_Size_MB': model_sizes_mb.get(size, 0)\n",
    "        })\n",
    "    \n",
    "    return comparison_results\n",
    "\n",
    "def visualize_model_comparison(comparison_results):\n",
    "    \"\"\"ëª¨ë¸ ë¹„êµ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    if not comparison_results:\n",
    "        print(\"âŒ No comparison results to visualize\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "    \n",
    "    # 1. mAP ë¹„êµ\n",
    "    bars1 = axes[0,0].bar(df['Model'], df['mAP50'], \n",
    "                         color=colors[:len(df)], alpha=0.8, edgecolor='black')\n",
    "    axes[0,0].set_title('mAP@0.5 Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0,0].set_ylabel('mAP@0.5')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ê°’ í‘œì‹œ\n",
    "    for bar, value in zip(bars1, df['mAP50']):\n",
    "        axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. FPS ë¹„êµ\n",
    "    bars2 = axes[0,1].bar(df['Model'], df['FPS'], \n",
    "                         color=colors[:len(df)], alpha=0.8, edgecolor='black')\n",
    "    axes[0,1].set_title('Inference Speed Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0,1].set_ylabel('FPS')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ê°’ í‘œì‹œ\n",
    "    for bar, value in zip(bars2, df['FPS']):\n",
    "        axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                      f'{value:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. ëª¨ë¸ í¬ê¸° ë¹„êµ\n",
    "    bars3 = axes[1,0].bar(df['Model'], df['Model_Size_MB'], \n",
    "                         color=colors[:len(df)], alpha=0.8, edgecolor='black')\n",
    "    axes[1,0].set_title('Model Size Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1,0].set_ylabel('Size (MB)')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ê°’ í‘œì‹œ\n",
    "    for bar, value in zip(bars3, df['Model_Size_MB']):\n",
    "        axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                      f'{value}MB', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 4. ì •í™•ë„ vs ì†ë„ ì‚°ì ë„\n",
    "    scatter = axes[1,1].scatter(df['FPS'], df['mAP50'], \n",
    "                               s=df['Model_Size_MB']*5, \n",
    "                               c=range(len(df)), cmap='viridis',\n",
    "                               alpha=0.7, edgecolors='black', linewidth=2)\n",
    "    \n",
    "    # ëª¨ë¸ ì´ë¦„ í‘œì‹œ\n",
    "    for i, model in enumerate(df['Model']):\n",
    "        axes[1,1].annotate(model, (df['FPS'].iloc[i], df['mAP50'].iloc[i]),\n",
    "                          xytext=(5, 5), textcoords='offset points',\n",
    "                          fontweight='bold', fontsize=10)\n",
    "    \n",
    "    axes[1,1].set_xlabel('FPS (Higher is Better)')\n",
    "    axes[1,1].set_ylabel('mAP@0.5 (Higher is Better)')\n",
    "    axes[1,1].set_title('Accuracy vs Speed Trade-off\\n(Bubble size = Model size)', \n",
    "                       fontsize=14, fontweight='bold')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"âœ… Model comparison saved to: model_comparison.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“Š MODEL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(df.round(3).to_string(index=False))\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9565fd",
   "metadata": {},
   "source": [
    "5ë‹¨ê³„: ì‹¤ì œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"ì „ì²´ ì‹¤ìŠµ ë©”ì¸ í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸš€ YOLOv11 Traffic Sign Detection System\")\n",
    "    print(\"=\"*60)\n",
    "    original_dir = nuclear_mlflow_disable()\n",
    "    try:\n",
    "        # 1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "        print(\"\\nğŸ“¥ Step 1: Downloading dataset...\")\n",
    "        dataset_path = download_traffic_dataset_roboflow()\n",
    "        print(f\"âœ… Dataset ready at: {dataset_path}\")\n",
    "        \n",
    "        # 2. ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨\n",
    "        print(\"\\nğŸƒâ€â™‚ï¸ Step 2: Training YOLOv11 model...\")\n",
    "        model, results = train_yolov11_model(dataset_path, model_size='n', epochs=20)\n",
    "        \n",
    "        if model is None:\n",
    "            print(\"âŒ Training failed, exiting...\")\n",
    "            return\n",
    "        \n",
    "        # 3. ì„±ëŠ¥ í‰ê°€\n",
    "        print(\"\\nğŸ“Š Step 3: Evaluating performance...\")\n",
    "        performance = evaluate_model_performance(model, dataset_path)\n",
    "        speed = measure_inference_speed(model, dataset_path)\n",
    "        \n",
    "        # 4. ê²°ê³¼ ì‹œê°í™”\n",
    "        print(\"\\nğŸ“ˆ Step 4: Visualizing results...\")\n",
    "        visualize_training_results('traffic_signs_yolov11/yolo11n_experiment')\n",
    "        visualize_detection_results(model, dataset_path)\n",
    "        \n",
    "        # 5. ëª¨ë¸ ë¹„êµ (ì„ íƒì‚¬í•­)\n",
    "        compare_models = input(\"\\nâ“ Compare multiple model sizes? (y/n): \").lower().strip() == 'y'\n",
    "        \n",
    "        if compare_models:\n",
    "            print(\"\\nğŸ† Step 5: Comparing model variants...\")\n",
    "            comparison_results = compare_model_sizes(dataset_path, ['n', 's'], epochs=10)\n",
    "            if comparison_results:\n",
    "                visualize_model_comparison(comparison_results)\n",
    "        \n",
    "        # 6. ìš”ì•½ ì¶œë ¥\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ‰ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š Final Performance:\")\n",
    "        print(f\"   mAP@0.5: {performance['mAP50']:.3f}\")\n",
    "        print(f\"   mAP@0.5:0.95: {performance['mAP50_95']:.3f}\")\n",
    "        print(f\"   FPS: {speed['fps']:.1f}\")\n",
    "        print(f\"   Avg inference time: {speed['avg_time']:.3f}s\")\n",
    "        print(\"\\nğŸ“ Generated files:\")\n",
    "        print(\"   - training_analysis.png: Training process visualization\")\n",
    "        print(\"   - detection_results.png: Sample detection results\")\n",
    "        print(\"   - model_comparison.png: Model comparison (if selected)\")\n",
    "        print(\"   - trained model: traffic_signs_yolov11/yolo11n_experiment/weights/best.pt\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸ Training interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe2b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "start",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
