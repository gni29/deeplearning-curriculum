{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cb516f",
   "metadata": {},
   "source": [
    "실습 정리 및 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e3031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy.special import kl_div\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정 (선택사항)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# 시드 설정\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538d45f",
   "metadata": {},
   "source": [
    "5.1 오늘 학습한 핵심 개념 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5962d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📚 3일차 실습 핵심 개념 정리\n",
      "============================================================\n",
      "\n",
      "1. 확률분포의 성질\n",
      "----------------------------------------\n",
      "• 정규분포: 68-95-99.7 규칙, 중심극한정리\n",
      "• 베르누이분포: 평균=p, 분산=p(1-p), 최대분산은 p=0.5\n",
      "• 이항분포: 베르누이 시행의 합, 정규분포로 근사 가능\n",
      "\n",
      "2. 정보 이론 핵심\n",
      "----------------------------------------\n",
      "• 정보량: I(x) = -log₂(P(x)), 확률이 낮을수록 정보량 많음\n",
      "• 엔트로피: H(X) = E[I(X)], 불확실성의 측정, 균등분포에서 최대\n",
      "• 크로스 엔트로피: H(P,Q) = -Σ P(x)log Q(x), 모델 평가에 사용\n",
      "\n",
      "3. KL Divergence\n",
      "----------------------------------------\n",
      "• 정의: D_KL(P||Q) = Σ P(x)log(P(x)/Q(x))\n",
      "• 의미: Q 모델로 P 데이터를 인코딩할 때의 추가 비용\n",
      "• 성질: 비음성, 비대칭, P=Q일 때만 0\n",
      "\n",
      "4. VAE와 정보 이론\n",
      "----------------------------------------\n",
      "• 사전분포: 항상 N(0,I), 모든 데이터에 대해 동일\n",
      "• 사후분포: q(z|x), 입력에 따라 다름, 학습을 통해 변화\n",
      "• ELBO = 재구성 품질 - KL 발산, 최대화가 목표\n",
      "\n",
      "5. 실용적 관점\n",
      "----------------------------------------\n",
      "• KL ≈ 0: Posterior collapse, 정보 손실\n",
      "• KL = 3~15: 건강한 범위, 좋은 표현 학습\n",
      "• VAE Loss = -ELBO, 음수일수록 좋음\n",
      "\n",
      "============================================================\n",
      "🎯 내일 학습 예고: Jensen's Inequality와 ELBO 완전 유도\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def summarize_concepts():\n",
    "    \"\"\"오늘 학습한 핵심 개념들을 정리\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"📚 3일차 실습 핵심 개념 정리\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    concepts = {\n",
    "        \"1. 확률분포의 성질\": [\n",
    "            \"• 정규분포: 68-95-99.7 규칙, 중심극한정리\",\n",
    "            \"• 베르누이분포: 평균=p, 분산=p(1-p), 최대분산은 p=0.5\",\n",
    "            \"• 이항분포: 베르누이 시행의 합, 정규분포로 근사 가능\"\n",
    "        ],\n",
    "        \n",
    "        \"2. 정보 이론 핵심\": [\n",
    "            \"• 정보량: I(x) = -log₂(P(x)), 확률이 낮을수록 정보량 많음\",\n",
    "            \"• 엔트로피: H(X) = E[I(X)], 불확실성의 측정, 균등분포에서 최대\",\n",
    "            \"• 크로스 엔트로피: H(P,Q) = -Σ P(x)log Q(x), 모델 평가에 사용\"\n",
    "        ],\n",
    "        \n",
    "        \"3. KL Divergence\": [\n",
    "            \"• 정의: D_KL(P||Q) = Σ P(x)log(P(x)/Q(x))\",\n",
    "            \"• 의미: Q 모델로 P 데이터를 인코딩할 때의 추가 비용\",\n",
    "            \"• 성질: 비음성, 비대칭, P=Q일 때만 0\"\n",
    "        ],\n",
    "        \n",
    "        \"4. VAE와 정보 이론\": [\n",
    "            \"• 사전분포: 항상 N(0,I), 모든 데이터에 대해 동일\",\n",
    "            \"• 사후분포: q(z|x), 입력에 따라 다름, 학습을 통해 변화\",\n",
    "            \"• ELBO = 재구성 품질 - KL 발산, 최대화가 목표\"\n",
    "        ],\n",
    "        \n",
    "        \"5. 실용적 관점\": [\n",
    "            \"• KL ≈ 0: Posterior collapse, 정보 손실\",\n",
    "            \"• KL = 3~15: 건강한 범위, 좋은 표현 학습\",\n",
    "            \"• VAE Loss = -ELBO, 음수일수록 좋음\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for topic, points in concepts.items():\n",
    "        print(f\"\\n{topic}\")\n",
    "        print(\"-\" * 40)\n",
    "        for point in points:\n",
    "            print(point)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎯 내일 학습 예고: Jensen's Inequality와 ELBO 완전 유도\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# 실행\n",
    "summarize_concepts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bd5b1",
   "metadata": {},
   "source": [
    "5.2 실습 숙제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c170e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 3일차 숙제 문제\n",
      "==================================================\n",
      "\n",
      "문제 1: KL Divergence 직접 계산\n",
      "------------------------------\n",
      "  두 정규분포 N(1, 2²)과 N(-1, 1²) 사이의 KL Divergence를\n",
      "  해석적 공식과 수치적 방법으로 각각 계산하고 비교하세요.\n",
      "  오차가 0.001 이하가 되도록 수치적 계산의 정확도를 높여보세요.\n",
      "\n",
      "문제 2: 정보량과 압축의 관계\n",
      "------------------------------\n",
      "  다음 문자열들의 엔트로피를 계산하고,\n",
      "  'MISSISSIPPI', 'ABCDEFGHIJK', 'AAAAABBBBB'\n",
      "  각각에 대해 최적 압축률을 예측해보세요.\n",
      "  실제 ZIP 압축과 비교해보세요.\n",
      "\n",
      "문제 3: VAE 사후분포 시뮬레이션\n",
      "------------------------------\n",
      "  5개 클래스를 가진 데이터셋에서 VAE 학습을 시뮬레이션하세요.\n",
      "  각 epoch마다 사후분포의 평균과 분산을 기록하고,\n",
      "  KL divergence와 재구성 품질의 변화를 그래프로 그려보세요.\n",
      "\n",
      "문제 4: Jensen's Inequality 실험\n",
      "------------------------------\n",
      "  다양한 오목함수(log, sqrt, x^0.5)에 대해 Jensen's Inequality를 확인하세요.\n",
      "  볼록함수(x², exp)에 대해서는 부등호 방향이 바뀌는지 확인하세요.\n",
      "  ELBO 유도에서 Jensen's Inequality가 어떻게 사용되는지 설명하세요.\n",
      "\n",
      "==================================================\n",
      "💡 힌트: 오늘 실습 코드를 참고하여 문제를 해결해보세요!\n",
      "📅 제출: 내일 오전 수업 전까지\n"
     ]
    }
   ],
   "source": [
    "def homework_problems():\n",
    "    \"\"\"3일차 숙제 문제들\"\"\"\n",
    "    \n",
    "    print(\"📝 3일차 숙제 문제\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    problems = [\n",
    "        {\n",
    "            \"번호\": \"문제 1\",\n",
    "            \"제목\": \"KL Divergence 직접 계산\",\n",
    "            \"내용\": [\n",
    "                \"두 정규분포 N(1, 2²)과 N(-1, 1²) 사이의 KL Divergence를\",\n",
    "                \"해석적 공식과 수치적 방법으로 각각 계산하고 비교하세요.\",\n",
    "                \"오차가 0.001 이하가 되도록 수치적 계산의 정확도를 높여보세요.\"\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"번호\": \"문제 2\", \n",
    "            \"제목\": \"정보량과 압축의 관계\",\n",
    "            \"내용\": [\n",
    "                \"다음 문자열들의 엔트로피를 계산하고,\",\n",
    "                \"'MISSISSIPPI', 'ABCDEFGHIJK', 'AAAAABBBBB'\",\n",
    "                \"각각에 대해 최적 압축률을 예측해보세요.\",\n",
    "                \"실제 ZIP 압축과 비교해보세요.\"\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"번호\": \"문제 3\",\n",
    "            \"제목\": \"VAE 사후분포 시뮬레이션\", \n",
    "            \"내용\": [\n",
    "                \"5개 클래스를 가진 데이터셋에서 VAE 학습을 시뮬레이션하세요.\",\n",
    "                \"각 epoch마다 사후분포의 평균과 분산을 기록하고,\",\n",
    "                \"KL divergence와 재구성 품질의 변화를 그래프로 그려보세요.\"\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"번호\": \"문제 4\",\n",
    "            \"제목\": \"Jensen's Inequality 실험\",\n",
    "            \"내용\": [\n",
    "                \"다양한 오목함수(log, sqrt, x^0.5)에 대해 Jensen's Inequality를 확인하세요.\",\n",
    "                \"볼록함수(x², exp)에 대해서는 부등호 방향이 바뀌는지 확인하세요.\",\n",
    "                \"ELBO 유도에서 Jensen's Inequality가 어떻게 사용되는지 설명하세요.\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for problem in problems:\n",
    "        print(f\"\\n{problem['번호']}: {problem['제목']}\")\n",
    "        print(\"-\" * 30)\n",
    "        for line in problem['내용']:\n",
    "            print(f\"  {line}\")\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"💡 힌트: 오늘 실습 코드를 참고하여 문제를 해결해보세요!\")\n",
    "    print(\"📅 제출: 내일 오전 수업 전까지\")\n",
    "\n",
    "# 실행\n",
    "homework_problems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d01970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "start",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
